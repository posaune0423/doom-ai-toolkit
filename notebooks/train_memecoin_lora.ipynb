{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Toolkit by Ostris\n",
    "## Memecoin Multi-Concept LoRA Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/posaune0423/doom-ai-toolkit.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your image dataset in the `dataset/` folder at the repo root. This repo already includes the memecoin data in that location, so no extra setup is required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd doom-ai-toolkit && git submodule update --init --recursive && pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model License\n",
    "FLUX.1-schnell is Apache 2.0 and does not require a gated Hugging Face token, but you still need to agree to the model terms on Hugging Face and keep a token handy if you plan to access private models. Use the next cell to set `HF_TOKEN` when needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "SECRET_NAME = \"HF_TOKEN\"\n",
    "\n",
    "from google.colab import userdata  # type: ignore\n",
    "\n",
    "hf_token = userdata.get(SECRET_NAME)\n",
    "if not hf_token:\n",
    "    raise RuntimeError(\n",
    "        f\"Failed to retrieve required Hugging Face token from Colab secret '{SECRET_NAME}'.\"\n",
    "    )\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = hf_token\n",
    "print(f\"HF_TOKEN environment variable has been set from Colab secret '{SECRET_NAME}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/doom-ai-toolkit')\n",
    "from toolkit.job import run_job\n",
    "import yaml\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This is your config. It is documented pretty well. The configuration is loaded from a YAML file. This will run as is without modification, but feel free to edit as you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "config_path = Path('/content/doom-ai-toolkit/config/train_memecoin_multi_lora.yaml')\n",
    "with config_path.open('r') as f:\n",
    "    job_config = yaml.safe_load(f)\n",
    "print('Configuration loaded')\n",
    "print(f\"Training: {job_config['config']['name']}\")\n",
    "print(f\"Datasets: {len(job_config['config']['process'][0]['datasets'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it\n",
    "\n",
    "Below does all the magic. Check your folders to the left. Items will be in output/memecoin_multi_lora_v1. In the samples folder, there are periodic samples. This doesn't work great with colab. They will be in /content/doom-ai-toolkit/output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_job(job_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "Check your output dir and get your LoRA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "samples_dir = '/content/doom-ai-toolkit/output/memecoin_multi_lora_v1/samples'\n",
    "if os.path.exists(samples_dir):\n",
    "    images = sorted([f for f in os.listdir(samples_dir) if f.endswith('.png')])\n",
    "    for img in images[-6:]:\n",
    "        display(Image(filename=os.path.join(samples_dir, img)))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
