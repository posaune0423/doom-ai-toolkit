{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Toolkit by Ostris\n",
        "## Solana Logo Single-Concept LoRA Training\n",
        "\n",
        "This notebook trains a single-concept LoRA dedicated to the `cgl_sol` logo using `config/train_sol_lora.yaml`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "if os.path.exists('doom-ai-toolkit'):\n",
        "    subprocess.run(['git', '-C', 'doom-ai-toolkit', 'pull', 'origin', 'main'], check=True)\n",
        "    print('Repository updated successfully')\n",
        "else:\n",
        "    subprocess.run(['git', 'clone', 'https://github.com/posaune0423/doom-ai-toolkit.git'], check=True)\n",
        "    print('Repository cloned successfully')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook uses the dataset included in the repository as-is. The dataset for the Solana-like logo is already stored under `dataset/sol/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd doom-ai-toolkit && git submodule update --init --recursive && pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "!pip install --quiet --force-reinstall --no-deps numpy==1.26.3\n",
        "\n",
        "os.kill(os.getpid(), 9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model License\n",
        "FLUX.1-schnell is licensed under Apache 2.0. You may need to agree to the model terms on Hugging Face and set `HF_TOKEN` if required.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "SECRET_NAME = \"HF_TOKEN\"\n",
        "\n",
        "from google.colab import userdata  # type: ignore\n",
        "\n",
        "hf_token = userdata.get(SECRET_NAME)\n",
        "if not hf_token:\n",
        "    raise RuntimeError(\n",
        "        f\"Failed to retrieve required Hugging Face token from Colab secret '{SECRET_NAME}'.\"\n",
        "    )\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "print(f\"HF_TOKEN environment variable has been set from Colab secret '{SECRET_NAME}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/doom-ai-toolkit')\n",
        "from toolkit.job import run_job\n",
        "import yaml\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "This cell loads the configuration file for the Solana logo LoRA, stored at `config/train_sol_lora.yaml`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "config_path = Path('/content/doom-ai-toolkit/config/train_sol_lora.yaml')\n",
        "job_to_run = yaml.safe_load(config_path.read_text())\n",
        "print('Configuration loaded')\n",
        "print(f\"Training: {job_to_run['config']['name']}\")\n",
        "print(f\"Datasets: {len(job_to_run['config']['process'][0]['datasets'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run it\n",
        "\n",
        "Running `run_job` in the next cell will start training the Solana logo LoRA. Outputs will be saved under `/content/doom-ai-toolkit/output/sol_logo_lora` (the exact folder name depends on the run name).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_job(job_to_run)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Done\n",
        "\n",
        "After training finishes, you can retrieve the LoRA weights from the `output/` directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "base_output_dir = Path('/content/doom-ai-toolkit/output')\n",
        "\n",
        "# Collect all \"*/samples\" directories under output and pick the most recently updated one\n",
        "sample_dirs = [p for p in base_output_dir.glob('*/samples') if p.is_dir()]\n",
        "if sample_dirs:\n",
        "    samples_dir = sorted(sample_dirs, key=lambda p: p.stat().st_mtime)[-1]\n",
        "    print(f'Using samples_dir: {samples_dir}')\n",
        "\n",
        "    images = sorted([f for f in os.listdir(samples_dir) if f.endswith('.png')])\n",
        "    for img in images[-6:]:\n",
        "        display(Image(filename=os.path.join(samples_dir, img)))\n",
        "else:\n",
        "    print(f'No samples directory found under {base_output_dir}')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
